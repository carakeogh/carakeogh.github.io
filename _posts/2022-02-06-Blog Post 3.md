---
layout: post
post: Blog Post 3
---

In this blog post, I am going to describe how to make a web scraper. We will be scraping information from IMDB. Here is the link to my github project respository: [Blog Post 3](https://github.com/carakeogh/BlogPost3)

The idea of this project is to build a recommendation tool that suggests movies or tv shows you might like, based on if they share actors with your favorite tv show or movie. To do this, your web scraper will get information by navigating through the IMDB website. It will start on the IMDB page of your favorite tv show or movie, then it will find the cast that worked on that movie, and then it will find other tv shows or movies that the cast members have been in.

# Setup

To begin the process, we create a new GitHub repository to house the scraper and files that will be created in the process. Then, we open the terminal in the location of the repository and run these three lines: 


```python
conda activate PIC16B

scrapy startproject IMDB_scraper

cd IMDB_scraper
```

The first line activates the PIC16B environment on your computer. The next two lines create a lot of files, most of which you do not need to edit. In the file `settings.py`, add the  line below, which will limit the amount of pages you scrape when testing out your program.


```python
CLOSESPIDER_PAGECOUNT = 20
```

# Write Your Scraper

As always, we start by importing our packages, so we run:


```python
import scrapy
```

In your repository, a folder called IMDB_scraper was created when you ran the `startproject` line above. Inside that folder is another of the same name, and inside that is a folder called `spiders`. We create a file inside this `spiders` directory called `imdb_spider.py` with the code below. A spider allows you to "crawl" over websites and scrape their data. We also specify the `start_urls`, which is the URL of the IMDB page with your favorite TV show or movie. I chose the url for one of my favorite shows, "Brooklyn Nine-Nine".


```python
class ImdbSpider(scrapy.Spider):
    name = 'imdb_spider'
    
    start_urls = ['https://www.imdb.com/title/tt2467372/?ref_=fn_al_tt_1']
```

Note that we created a class, `ImdbSpider(scrapy.Spider)`, which will contain the three parsing methods that we will implement.

You should test out your spider in the scrapy shell before you run the spider. The scrapy shell is good for testing your data extraction code, and you can do this while you are writing your functions as a way to check if you are actually scraping the the data you want. You do this by running the code below in your terminal:


```python
scrapy shell 'https://www.imdb.com/title/tt2467372/?ref_=fn_al_tt_1'
```

Then you can run lines you want to test, such as `response.css("div.SubNav__SubNavContent-sc-11106ua-3.cKmYsV").css("li.ipc-inline-list__item a")[0].attrib["href"]`, which I explain below. To end the scrapy shell, you can type `exit` in your terminal.

The `parse` methods tell the spider what to do when it encounters a `response`. A response is an object corresponding to a webpage; it contains the raw HTML as well as a number of useful attributes and methods for extracting information from the page. The scrapy stores the website information with `response`. We call other functions with the `callback` argument in `scrapy.Request`.

### Parsing Method 1

This method works by finding the "Cast and Crew" link on the IMDB home page of the movie or TV show we choose as our favorite. To do this, we can use *Developer Tools* to view the html that goes into making the webpage. On a mac, you can access this by going to 'View'-->'Developer'-->'Developer Tools', or you can right-click on a specific part of the webpage and click 'Inspect'. We can then look through the html to find the `Element` that defines what we want to select. We can then use the css selectors `response.css("Element")` to get what we want. In this method we also use `.attrib["href"]`, which returns attributes for the first matching element of the link, signified by `href`. If the "Cast and Crew" link does in fact exist, then we follow the link and yield a request to call the subsequent method, `parse_full_credit(self, response).`


```python
    def parse(self, response):
        """
        This function assumes we start on the IMDB home page of a movie or TV show and then
        navigates to the "Cast and Crew" IMDB page. When it arrives at this page, the function 
        calls parse_full_credits(self, response). This function does not return any data.
        """
        
        #finds the "Cast and Crew" link on the home page
        next_page = response.css("div.SubNav__SubNavContent-sc-11106ua-3.cKmYsV").css("li.ipc-inline-list__item a")[0].attrib["href"]

        if next_page:
            cast_page = response.urljoin(next_page)
            
            #follows the link and calls the parse_full_credits function
            yield scrapy.Request(cast_page, callback = self.parse_full_credits)
```

### Parsing Method 2

This method works by starting on the "Cast and Crew" page for the movie or TV show we selected and following the links to each actor's individual credits page. It works using the same approach as described above. If the  link to an actor's page does exist, then we follow the link and yield a request to call the subsequent method, `parse_actor_page(self, response).`


```python
     def parse_full_credits(self, response):
        """
        This function assumes it starts on the "Cast and Crew" IMDB page for a given movie
        or TV show. It yields a scrapy.Request for each actor listed on the page and 
        calls parse_actor_page(self, response). This function does not return any data.
        """
        
        #creates a list of relative paths for each actor
        next_credit = [a.attrib["href"] for a in response.css("td.primary_photo a")]

        #loop through an iterable of actors
        for credit in next_credit:
            if credit:
                next_link = response.urljoin(credit)
                
                #follows the link to actor's page; calls parse_actor_page
                yield scrapy.Request(next_link, callback = self.parse_actor_page)
```

### Parsing Method 3

This method works by starting on the actor's credits page and getting the actor's name and the name of each film or TV show that they are in. The difference in this method is we use `.get()`, which lets us extract the textual data; `::text` lets us select the text node that is a part of the film/TV show name section. Lastly, we yield a dictionary that contains the actor's name and the film/TV show that they are in as key-value pairs.


```python
    def parse_actor_page(self, response):
        """
        This function assumes it starts on the IMDB page of an actor. It gets the name 
        of the actor and the names of the films and/or tv shows the actor has been in.
        The function yields this information in the form of a dictionary.
        """

        #get actor's name from the header of IMDB page
        name_box = response.css("h1.header")
        actor_name = name_box.css("span.itemprop::text").get()
        
        #loop through an iterable of films and TV shows
        for film in response.css("div.filmo-category-section b"):

            #get name of film or TV show actor was in
            movie_or_TV_name = film.css("::text").get()

            #dictionary with the name of the actor and the film/TV show they were in
            ## as key value pairs
            if movie_or_TV_name:
                yield {
                    "actor" : actor_name, 
                    "movie_or_TV_name" : movie_or_TV_name
                }
```

# Make Your Recommendations

Once we have checked the functionality of our code in the scrapy shell and the spider is fully written, we can now run our spider and save the results in a csv file. First, comment out the line we added to the `settings.py` file.


```python
#CLOSESPIDER_PAGECOUNT = 20
```

Then, type this command in the terminal. This will run your spider and save the results to a CSV file called `movies.csv`, where the columns are (1) the actors' names and (2) the movies and TV shows that they have worked on.


```python
scrapy crawl imdb_spider -o movies.csv
```

Now that we have the CSV file, we can make a list of movies and TV shows, sorted by how many actors they share with your favorite movie or TV show. Then we can use this list as a recommendation for what to check out next. We will do this with our good friend, the `pandas` library.

We start by importing the `pandas` library and reading in the CSV we created.


```python
import pandas as pd
```


```python
df = pd.read_csv("movies.csv")
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>actor</th>
      <th>movie_or_TV_name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Jim O'Heir</td>
      <td>The Fall</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Sarah Baker</td>
      <td>Young Sheldon</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Jim O'Heir</td>
      <td>Hardliner</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Jim O'Heir</td>
      <td>Breathing Happy</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Jim O'Heir</td>
      <td>Cock N' Bull 3</td>
    </tr>
  </tbody>
</table>
</div>



Then we can manipulate our dataframe to count the number of actors for each movie/TV show in our dataset with `df.value_counts`.


```python
df = pd.DataFrame(df.value_counts(subset = "movie_or_TV_name"))

#rename count column
df = df.rename(columns = {0 : "number of shared actors"})
```

Finally, we can view our dataframe. The top choice will usually be your favorite movie or TV show that you started with because it shares the most actors with itself. We can look at the next rows and get a good deal of recommendations. Since I loved Brooklyn Nine-Nine, I might also enjoy Entertainment Tonight!


```python
df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>number of shared actors</th>
    </tr>
    <tr>
      <th>movie_or_TV_name</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Brooklyn Nine-Nine</th>
      <td>36</td>
    </tr>
    <tr>
      <th>Entertainment Tonight</th>
      <td>12</td>
    </tr>
    <tr>
      <th>The Tonight Show Starring Jimmy Fallon</th>
      <td>8</td>
    </tr>
    <tr>
      <th>Saturday Night Live</th>
      <td>8</td>
    </tr>
    <tr>
      <th>Made in Hollywood</th>
      <td>7</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>How2 Make It As an Actor</th>
      <td>1</td>
    </tr>
    <tr>
      <th>How to Make the Cruelest Month</th>
      <td>1</td>
    </tr>
    <tr>
      <th>How Sex Changed the World</th>
      <td>1</td>
    </tr>
    <tr>
      <th>How Murray Saved Christmas</th>
      <td>1</td>
    </tr>
    <tr>
      <th>iMurder</th>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>2418 rows Ã— 1 columns</p>
</div>


